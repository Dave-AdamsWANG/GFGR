{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rl/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 965 new token.\n",
      "data num: 131413\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import sys\n",
    "from typing import List\n",
    "from modeling_letter import LETTER\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn \n",
    "# from peft import PeftModel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, LlamaConfig, T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "import types\n",
    "from utils import *\n",
    "from collator import TestCollator, Collator\n",
    "from evaluate import get_topk_results, get_metrics_results\n",
    "from generation_trie import Trie\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "# from trl.core import respond_to_batch\n",
    "\n",
    "class SimpleArgs:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "def get_keys_by_value(my_dict, target_value):\n",
    "    keys = [int(key) for key, value in my_dict.items() if value == target_value]\n",
    "    if len(keys)==0:\n",
    "        keys.append(0)\n",
    "    elif len(keys)>1:\n",
    "        keys=keys[:1]\n",
    "    return keys\n",
    "args = SimpleArgs(\n",
    "    seed=42,\n",
    "    gpu_id=0,\n",
    "    tasks=\"seqrec\",\n",
    "    dataset=\"Beauty\",\n",
    "    index_file=\".index.json\",\n",
    "    data_path=\"/root/LETTER/data\",\n",
    "    his_sep=\", \",\n",
    "    max_his_len=20,\n",
    "    only_train_response=False,\n",
    "    add_prefix=False,\n",
    "    train_prompt_sample_num=\"1\",\n",
    "    train_data_sample_num=\"-1\",\n",
    "    valid_prompt_id=0,\n",
    "    sample_valid=True,\n",
    "    valid_prompt_sample_num=2,\n",
    "    ckpt_path=\"./ckpt/Instruments/checkpoint-3465\",\n",
    "    results_file=\"./results/$DATASET/res.json\",\n",
    "    test_task=\"SeqRec\",\n",
    "    test_prompt_ids=\"0\",\n",
    "    sample_num=-1,\n",
    "    num_beams=20,\n",
    "    test_batch_size=20,\n",
    "    rl_type='dpo',\n",
    "    rl_neg_num=1\n",
    ")\n",
    "set_seed(args.seed)\n",
    "\n",
    "device_map = {\"\": args.gpu_id}\n",
    "device = torch.device(\"cuda\",args.gpu_id)\n",
    "\n",
    "config = T5Config.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    \"t5-small\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "train_data, valid_data = load_datasets(args)\n",
    "add_num = tokenizer.add_tokens(train_data.get_new_tokens())\n",
    "config.vocab_size = len(tokenizer)\n",
    "\n",
    "print(\"add {} new token.\".format(add_num))\n",
    "print(\"data num:\", len(train_data))\n",
    "\n",
    "with open(os.path.join(os.path.join(args.data_path, args.dataset), args.dataset + args.index_file), 'r') as f:\n",
    "    indices = json.load(f)\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(args.ckpt_path)\n",
    "model = LETTER(config)\n",
    "#model.set_hyper(args.temperature)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\n",
    "#     args.ckpt_path,\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     device_map=device_map,\n",
    "# )\n",
    "prompt_ids = [0]\n",
    "\n",
    "test_data = load_test_dataset(args)\n",
    "\n",
    "\n",
    "all_items = test_data.get_all_items()\n",
    "\n",
    "\n",
    "\n",
    "candidate_trie = Trie(\n",
    "        [\n",
    "            [0] + tokenizer.encode(candidate)\n",
    "            for candidate in all_items\n",
    "        ]\n",
    "    )\n",
    "prefix_allowed_tokens = prefix_allowed_tokens_fn(candidate_trie)\n",
    "\n",
    "# # collator = TestCollator(args, tokenizer)\n",
    "# collator = Collator(args, tokenizer)\n",
    "# train_loader = DataLoader(train_data,collate_fn=collator,batch_size=20)\n",
    "# # test_loader = DataLoader(test_data, batch_size=args.test_batch_size, collate_fn=collator,\n",
    "#                             # shuffle=True, num_workers=4, pin_memory=True)\n",
    "# for i in train_loader:\n",
    "#     break\n",
    "from datasets import Dataset\n",
    "def data_converter(data):\n",
    "    data_list = []\n",
    "    for i in range(len(data)):\n",
    "        data_list.append(data[i])\n",
    "    data_dict = {key: [item[key] for item in data_list] for key in data_list[0].keys()}\n",
    "    return data_dict, Dataset.from_dict(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in  ['Beauty','Yelp']:\n",
    "    # for index in ['.index.json','.new.index.json']:\n",
    "    args.dataset=dataset\n",
    "    train_data, valid_data = load_datasets(args)\n",
    "    add_num = tokenizer.add_tokens(train_data.get_new_tokens())\n",
    "    config.vocab_size = len(tokenizer)\n",
    "    train_dict, train_data = data_converter(train_data)\n",
    "    valid_dict, valid_data = data_converter(valid_data) # Initial state\n",
    "    ensure_dir(f'/root/LETTER/data/{dataset}/dpo/')\n",
    "    with open( f'/root/LETTER/data/{dataset}/dpo/train0.json', 'w') as f:\n",
    "        for item in train_data:\n",
    "            json.dump(item, f)  \n",
    "            f.write('\\n')\n",
    "    with open( f'/root/LETTER/data/{dataset}/dpo/valid0.json', 'w') as f:\n",
    "        for item in valid_data:\n",
    "            json.dump(item, f)  \n",
    "            f.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30431"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dict['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.index_file=\".new.index.json\"\n",
    "\n",
    "for dataset in  ['Beauty','Yelp']:\n",
    "    # for index in ['.index.json','.new.index.json']:\n",
    "    args.dataset=dataset\n",
    "    train_data, valid_data = load_datasets(args)\n",
    "    add_num = tokenizer.add_tokens(train_data.get_new_tokens())\n",
    "    config.vocab_size = len(tokenizer)\n",
    "    train_dict, train_data = data_converter(train_data)\n",
    "    valid_dict, valid_data = data_converter(valid_data) # Initial state\n",
    "    ensure_dir(f'/root/LETTER/data/{dataset}/dpo/')\n",
    "    with open( f'/root/LETTER/data/{dataset}/dpo/new-train0.json', 'w') as f:\n",
    "        for item in train_data:\n",
    "            json.dump(item, f)  \n",
    "            f.write('\\n')\n",
    "    with open( f'/root/LETTER/data/{dataset}/dpo/new-valid0.json', 'w') as f:\n",
    "        for item in valid_data:\n",
    "            json.dump(item, f)  \n",
    "            f.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset='Beauty'\n",
    "args.index_file=\".index.json\"\n",
    "args.rl_type='sprec'\n",
    "args.per_device_batch_size=1024\n",
    "args.num_beams=5\n",
    "if 'new' in args.index_file:\n",
    "    train_json_file = f\"/root/LETTER/data/{args.dataset}/dpo/new-train0.json\"\n",
    "    valid_json_file = f\"/root/LETTER/data/{args.dataset}/dpo/new-valid0.json\"\n",
    "else:\n",
    "    train_json_file = f\"/root/LETTER/data/{args.dataset}/dpo/train0.json\"\n",
    "    valid_json_file = f\"/root/LETTER/data/{args.dataset}/dpo/valid0.json\"\n",
    "# with open(train_json_file, 'r') as f:\n",
    "#     train_data = json.load(f)\n",
    "# with open(valid_json_file, 'r') as f:\n",
    "#     valid_data = json.load(f)\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"json\", data_files=train_json_file)\n",
    "train_data = train_dataset[\"train\"]\n",
    "valid_dataset = load_dataset(\"json\", data_files=valid_json_file)\n",
    "val_data = valid_dataset[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(val_data,batch_size=1024, \n",
    "                             shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    f'/root/autodl-tmp/org_chkpt/ckpt/{args.dataset}/',\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=device_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_data={'prompt':[], 'chosen':[], 'rejected':[]}\n",
    "    prog_iter = tqdm(data_loader, leave=False, desc='Generating')\n",
    "    for batch in prog_iter:\n",
    "        inputs = tokenizer(batch['prompt'], \n",
    "            return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True)\n",
    "        output = model.generate(\n",
    "                        input_ids=inputs[\"input_ids\"].to(model.device),\n",
    "                        attention_mask=inputs[\"attention_mask\"].to(model.device),\n",
    "                        max_new_tokens=10,\n",
    "                        # max_length=10,\n",
    "                        prefix_allowed_tokens_fn=prefix_allowed_tokens,\n",
    "                        num_beams=args.num_beams,\n",
    "                        num_return_sequences=args.num_beams,\n",
    "                        output_scores=True,\n",
    "                        return_dict_in_generate=True,\n",
    "                        early_stopping=True,\n",
    "                    )\n",
    "        output_ids = output[\"sequences\"]\n",
    "        scores = output[\"sequences_scores\"]\n",
    "        output = tokenizer.batch_decode(\n",
    "                    output_ids, skip_special_tokens=True\n",
    "            )\n",
    "        predictions = [_.strip().replace(\" \",\"\") for _ in output]\n",
    "        if args.rl_type=='sprec':\n",
    "            new_rej = get_topk_results(predictions, scores, batch['chosen'], args.num_beams, all_items=all_items)\n",
    "        elif args.rl_type=='ipa':\n",
    "            response_items=torch.tensor([get_keys_by_value(indices,i.split(\" \")) for i in output]).to(device) \n",
    "            collab_score = colab_model.predict(torch.stack(batch['origin_inters'],0).to(device),response_items.reshape(-1,args.num_beams),torch.stack(batch['positions'],0).to(device)).sigmoid().flatten()\n",
    "            new_rej = get_topk_results(predictions, collab_score, batch['chosen'], args.num_beams, all_items=all_items)\n",
    "        batch['rejected'] = new_rej\n",
    "        for key in new_data.keys():\n",
    "            new_data[key]+=batch[key]\n",
    "    # return Dataset.from_dict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 22363\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_dict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    f'/root/autodl-tmp/org_chkpt/ckpt/{args.dataset}/',\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=device_map,\n",
    ")\n",
    "# reference_model = T5ForConditionalGeneration.from_pretrained(\n",
    "#     f'/root/autodl-tmp/org_chkpt/ckpt/{args.dataset}/',\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     device_map=device_map,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(prompts,completions, ground_truth,origin_item,origin_inters,positions):\n",
    "    print(prompts,completions, ground_truth,origin_item,origin_inters,positions)\n",
    "    response_items=torch.tensor([get_keys_by_value(train_data.indices,i.split(' ')[1:-1]) for i in completions])\n",
    "    print(response_items)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    for i in range(len(train_data)):\n",
    "        yield train_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = model(input_ids=\u001b[43mi\u001b[49m[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m].to(model.device),attention_mask=i[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(model.device),labels=i[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(model.device))\n",
      "\u001b[31mNameError\u001b[39m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "res = model(input_ids=i['input_ids'].to(model.device),attention_mask=i['attention_mask'].to(model.device),labels=i['labels'].to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = i['input_ids']\n",
    "attention_mask = i['attention_mask']\n",
    "\n",
    "actions = i['labels'].unsqueeze(1).repeat(1,2,1)\n",
    "def in_batch_negative_sampling(labels,origin_inters,positions,origin_item, N,collab_model):\n",
    "    B, L = labels.shape\n",
    "    if B<=N:\n",
    "        N=B\n",
    "    actions = torch.zeros((B, N, L), dtype=labels.dtype, device=labels.device) \n",
    "    actions[:, 0, :] = labels\n",
    "    reward = torch.tensor([1]+[0]*(N-1),device=labels.device,dtype=torch.float).unsqueeze(0).repeat_interleave(repeats=B,dim=0) # B,N; Basic Reward\n",
    "    if collab_model:\n",
    "        collab_pred = collab_model.predict(origin_inters,origin_item,positions).sigmoid() # B*B        \n",
    "    for i in range(B):\n",
    "        other_indices = [j for j in range(B) if j != i]\n",
    "        negative_indices = torch.randperm(len(other_indices))[:N - 1]\n",
    "        negative_samples = labels[torch.tensor(other_indices)[negative_indices]]\n",
    "        actions[i, 1:, :] = negative_samples\n",
    "        reward[i,:]+=collab_pred[i,torch.cat([torch.tensor(i).unsqueeze(0),torch.tensor(other_indices)[negative_indices]])]\n",
    "        reward[i,:]+=(negative_samples[:,:-1]==labels[i,:-1]).sum()/(L-1)\n",
    "    return actions, reward\n",
    "\n",
    "import torch\n",
    "\n",
    "def in_batch_negative_sampling_new(labels, origin_inters, positions, origin_item, N, collab_model):\n",
    "    B, L = labels.shape\n",
    "    if B <= N:\n",
    "        N = B\n",
    "    actions = torch.zeros((B, N, L), dtype=labels.dtype, device=labels.device)\n",
    "    actions[:, 0, :] = labels\n",
    "    reward = torch.tensor([1] + [0] * (N - 1), device=labels.device, dtype=torch.float).unsqueeze(0).repeat_interleave(repeats=B, dim=0) +0.5\n",
    "    all_indices = torch.arange(B, device=labels.device).repeat(B,1)\n",
    "    mask = ~torch.eye(B, dtype=torch.bool, device=labels.device)\n",
    "    other_indices_matrix = all_indices[mask].reshape(B, B - 1)\n",
    "    if collab_model:\n",
    "        collab_pred = collab_model.predict(origin_inters, origin_item, positions).sigmoid()\n",
    "        other_collab_pred = collab_pred.gather(1,other_indices_matrix)\n",
    "        if torch.rand(1).item() < 0.001:\n",
    "            negative_indices_matrix = torch.argsort(other_collab_pred, dim=-1)[:, :N - 1]\n",
    "        else:\n",
    "            negative_indices_matrix = torch.argsort(torch.randn([B, B - 1], device=labels.device), dim=-1)[:, :N - 1]\n",
    "        if epsilon< 0.9:\n",
    "            epsilon += 0.001\n",
    "            if epsilon>0.89:\n",
    "                print(epsilon)\n",
    "    else:\n",
    "        negative_indices_matrix = torch.argsort(torch.randn([B, B - 1], device=labels.device), dim=-1)[:, :N - 1]\n",
    "    negative_samples = labels[other_indices_matrix.gather(1, negative_indices_matrix)]\n",
    "    actions[:, 1:, :] = negative_samples\n",
    "    if collab_model:\n",
    "        self_indices = torch.arange(B, device=labels.device).unsqueeze(1)\n",
    "        selected_indices = torch.cat([self_indices, other_indices_matrix.gather(1, negative_indices_matrix)], dim=1)\n",
    "        reward *= collab_pred.gather(1, selected_indices)+0.5\n",
    "    partial_match = (negative_samples[:, :, :-1] == labels.unsqueeze(1)[:, :, :-1]).sum(dim=-1) / (L - 1)\n",
    "    reward *= partial_match+0.5\n",
    "    return actions, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39139/1408449542.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ns_res = in_batch_negative_sampling(i['labels'].to(model.device),torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['positions']).to(model.device),torch.tensor(i['origin_item']).to(model.device),2,colab_model)\n"
     ]
    }
   ],
   "source": [
    "collab_model_args = SimpleArgs(\n",
    "hidden_size=32,\n",
    "num_heads=1,\n",
    "trm_num=2,\n",
    "dropout_rate=0.5, \n",
    "max_len=20,\n",
    ")\n",
    "from models.Bert4Rec import Bert4Rec\n",
    "model_state_dict=torch.load('/root/GFGR/SeqRec/saved/Beauty/bert4rec/pytorch_model.bin')\n",
    "colab_model = Bert4Rec(1,model_state_dict['state_dict']['item_emb.weight'].shape[0]-2,model.device,collab_model_args)\n",
    "colab_model.load_state_dict(model_state_dict['state_dict'])\n",
    "colab_model.eval()\n",
    "colab_model.to(model.device)\n",
    "ns_res = in_batch_negative_sampling(i['labels'].to(model.device),torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['positions']).to(model.device),torch.tensor(i['origin_item']).to(model.device),2,colab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "colab_res = colab_model.predict(torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['origin_item']).to(model.device),torch.tensor(i['positions']).to(model.device))\n",
    "colab_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 μs, sys: 1e+03 ns, total: 8 μs\n",
      "Wall time: 15.5 μs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6889/3390489798.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ns_res = in_batch_negative_sampling(i['labels'].to(model.device),torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['positions']).to(model.device),torch.tensor(i['origin_item']).to(model.device),2,colab_model)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "set_seed(42)\n",
    "ns_res = in_batch_negative_sampling(i['labels'].to(model.device),torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['positions']).to(model.device),torch.tensor(i['origin_item']).to(model.device),2,colab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47 μs, sys: 7 μs, total: 54 μs\n",
      "Wall time: 15 μs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39139/1258502396.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ns_res_new = in_batch_negative_sampling_new(i['labels'].to(model.device),torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['positions']).to(model.device),torch.tensor(i['origin_item']).to(model.device),2,colab_model)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "set_seed(42)\n",
    "ns_res_new = in_batch_negative_sampling_new(i['labels'].to(model.device),torch.tensor(i['origin_inters']).to(model.device),torch.tensor(i['positions']).to(model.device),torch.tensor(i['origin_item']).to(model.device),2,colab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_train_rl_data(self):\n",
    "    def random_neq(candidates, s=[], neg_num=1):\n",
    "        # if neg_num > len(candidates):\n",
    "        #     return np.array(list(candidates))\n",
    "        neg_list = random.sample(list(candidates), neg_num)\n",
    "        return np.array(neg_list)\n",
    "    inter_data = []\n",
    "    all_items = set(self.indices.keys())\n",
    "    for uid  in self.remapped_inters:\n",
    "        items = self.remapped_inters[uid][:-2]\n",
    "        nonneg_items = self.inters[uid]\n",
    "        origin_items = nonneg_items[:-2]\n",
    "        \n",
    "        for i in range(1, len(items)):\n",
    "            one_data = dict()\n",
    "            # one_data[\"user\"] = uid\n",
    "            one_data[\"item\"] = items[i]\n",
    "            one_data[\"origin_item\"] = origin_items[i]\n",
    "            history = items[:i]\n",
    "            origin_history = origin_items[:i]\n",
    "            if self.max_his_len > 0:\n",
    "                history = history[-self.max_his_len:]\n",
    "                history_len =len(origin_history)\n",
    "            if history_len > self.max_his_len:\n",
    "                mask_len = 0\n",
    "                positions = list(range(1, self.max_his_len+1))\n",
    "                origin_history=origin_history[-self.max_his_len:]\n",
    "            else:\n",
    "                mask_len = self.max_his_len - history_len\n",
    "                positions = list(range(1, history_len+1))\n",
    "                origin_seq = np.zeros([self.max_his_len], dtype=np.int32)\n",
    "                origin_seq[-history_len:] = origin_history\n",
    "                origin_history = origin_seq\n",
    "            positions= positions[-self.max_his_len:]\n",
    "            positions = [0] * mask_len + positions\n",
    "            one_data[\"positions\"] = np.array(positions)\n",
    "            if self.add_prefix:\n",
    "                history = [str(k+1) + \". \" + item_idx for k, item_idx in enumerate(history)]\n",
    "            one_data[\"inters\"] = \"\".join(history)\n",
    "            one_data[\"origin_inters\"] = origin_history\n",
    "            neg_items = random_neq(all_items,nonneg_items,neg_num=1)\n",
    "            one_data[\"origin_neg\"] = neg_items\n",
    "            one_data[\"neg\"] = [\"\".join(self.indices[str(i)]) for i in neg_items] \n",
    "            inter_data.append(one_data)\n",
    "    return inter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_inter = _process_train_rl_data(train_data.datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLCollator(object):\n",
    "\n",
    "    def __init__(self, args, tokenizer):\n",
    "        self.args = args\n",
    "        self.only_train_response = args.only_train_response\n",
    "        self.tokenizer = tokenizer\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = 0\n",
    "        # print(self.tokenizer.model_max_length)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        if self.args.rl_type=='dpo':\n",
    "            prompt_texts = [d[\"prompt\"] for d in batch]\n",
    "            chosen_texts = [d[\"chosen\"] for d in batch]\n",
    "            rejected_texts = [d[\"rejected\"] for d in batch]\n",
    "            prompt = self.tokenizer(prompt_texts,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                    padding=\"longest\",\n",
    "                                    max_length=self.tokenizer.model_max_length,\n",
    "                                    truncation=True,\n",
    "                                    return_attention_mask=True)\n",
    "\n",
    "            chosen = self.tokenizer(chosen_texts,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                    padding=\"longest\",\n",
    "                                    max_length=self.tokenizer.model_max_length,\n",
    "                                    truncation=True,\n",
    "                                    return_attention_mask=True)\n",
    "            rejected = self.tokenizer(rejected_texts,\n",
    "                            return_tensors=\"pt\",\n",
    "                            padding=\"longest\",\n",
    "                            max_length=self.tokenizer.model_max_length,\n",
    "                            truncation=True,\n",
    "                            return_attention_mask=True)\n",
    "            return dict(prompt_input_ids=prompt[\"input_ids\"], prompt_attention_mask=prompt['attention_mask'],\n",
    "                chosen_input_ids=chosen[\"input_ids\"], chosen_attention_mask=chosen['attention_mask'],\n",
    "                rejected_input_ids=rejected[\"input_ids\"], rejected_attention_mask=rejected['attention_mask'])\n",
    "        else:\n",
    "            input_texts = [d[\"prompt\"] for d in batch]\n",
    "            label_texts = [d[\"ground_truth\"] for d in batch]\n",
    "\n",
    "            inputs = self.tokenizer(input_texts,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                    padding=\"longest\",\n",
    "                                    max_length=self.tokenizer.model_max_length,\n",
    "                                    truncation=True,\n",
    "                                    return_attention_mask=True)\n",
    "\n",
    "            labels = self.tokenizer(label_texts,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                    padding=\"longest\",\n",
    "                                    max_length=self.tokenizer.model_max_length,\n",
    "                                    truncation=True,\n",
    "                                    return_attention_mask=True)\n",
    "            inputs['labels'] = labels['input_ids']\n",
    "            inputs['labels'][inputs['labels'] == self.tokenizer.pad_token_id] = -100\n",
    "            origin_item= torch.tensor([d[\"origin_item\"] for d in batch]).to(prompt['input_ids'].device)\n",
    "            origin_inters=torch.tensor([d[\"origin_inters\"] for d in batch]).to(prompt['input_ids'].device)\n",
    "            positions = torch.tensor([d[\"positions\"] for d in batch]).to(prompt['input_ids'].device)\n",
    "\n",
    "            return dict(inputs=inputs,origin_item=origin_item,origin_inters=origin_inters,positions=positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = RLCollator(args,tokenizer)\n",
    "train_loader = DataLoader(train_data,collate_fn=collator,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trl \n",
    "model = trl.AutoModelForSeq2SeqLMWithValueHead(T5ForConditionalGeneration.from_pretrained(\n",
    "    f'/root/autodl-tmp/org_chkpt/ckpt/{args.dataset}/',\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=device_map,\n",
    "))\n",
    "model.is_peft_model=False\n",
    "# reference_model = T5ForConditionalGeneration.from_pretrained(\n",
    "#      f'/root/autodl-tmp/org_chkpt/ckpt/{args.dataset}/',\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     device_map=device_map,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert4Rec(\n",
       "  (item_emb): Embedding(12102, 32, padding_idx=0)\n",
       "  (pos_emb): Embedding(120, 32)\n",
       "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (backbone): BertBackbone(\n",
       "    (attention_layernorms): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((32,), eps=1e-08, elementwise_affine=True)\n",
       "    )\n",
       "    (attention_layers): ModuleList(\n",
       "      (0-1): 2 x MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (forward_layernorms): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((32,), eps=1e-08, elementwise_affine=True)\n",
       "    )\n",
       "    (forward_layers): ModuleList(\n",
       "      (0-1): 2 x PointWiseFeedForward(\n",
       "        (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (last_layernorm): LayerNorm((32,), eps=1e-08, elementwise_affine=True)\n",
       "  )\n",
       "  (loss_func): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_model_args = SimpleArgs(\n",
    "hidden_size=32,\n",
    "num_heads=1,\n",
    "trm_num=2,\n",
    "dropout_rate=0.5, \n",
    "max_len=20,\n",
    ")\n",
    "from models.Bert4Rec import Bert4Rec\n",
    "model_state_dict=torch.load('/root/GFGR/SeqRec/saved/Beauty/bert4rec/pytorch_model.bin')\n",
    "colab_model = Bert4Rec(1,model_state_dict['state_dict']['item_emb.weight'].shape[0]-2,model.pretrained_model.device,collab_model_args)\n",
    "colab_model.load_state_dict(model_state_dict['state_dict'])\n",
    "colab_model.eval()\n",
    "colab_model.to(model.pretrained_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ppo/lib/python3.13/site-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/ppo/lib/python3.13/site-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/root/miniconda3/envs/ppo/lib/python3.13/site-packages/trl/trainer/ppo_trainer.py:273: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ppo_config = PPOConfig(\n",
    "    batch_size=128,\n",
    ")\n",
    "ppo_trainer = PPOTrainer(config=ppo_config, model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_454754/1783928836.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  reward = (response_items.squeeze()==i['origin_item']).long().to(device).squeeze()+colab_model.predict(torch.tensor(i['origin_inters']).to(device),response_items.to(device),torch.tensor(i['positions']).to(device)).sigmoid().squeeze()\n"
     ]
    }
   ],
   "source": [
    "def get_keys_by_value(my_dict, target_value):\n",
    "    keys = [int(key) for key, value in my_dict.items() if value == target_value]\n",
    "    if len(keys)==0:\n",
    "        keys.append(-1)\n",
    "    return keys\n",
    "device = model.pretrained_model.device\n",
    "response_tensor=model.generate(input_ids=i['inputs']['input_ids'].to(device),attention_mask=i['inputs']['attention_mask'].to(device))\n",
    "decoded_response=[tokenizer.decode(i[1:-1]).split(' ') for i in response_tensor]\n",
    "response_items=torch.tensor([get_keys_by_value(train_data.indices,i) for i in decoded_response])\n",
    "reward = (response_items.squeeze()==i['origin_item']).long().to(device).squeeze()+colab_model.predict(torch.tensor(i['origin_inters']).to(device),response_items.to(device),torch.tensor(i['positions']).to(device)).sigmoid().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = ppo_trainer.step(list(i['inputs']['input_ids'].to(device).unbind(dim=0)), list(response_tensor.unbind(dim=0)), list(reward.unbind(dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective/kl': 0.0,\n",
       " 'objective/kl_dist': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'objective/logprobs': array([[-3.76126862e+00, -4.91392851e+00, -1.44429564e+00,\n",
       "         -3.39802384e-01,  0.00000000e+00],\n",
       "        [-3.30107641e+00, -1.97480762e+00, -1.94255662e+00,\n",
       "         -7.31331706e-01,  0.00000000e+00],\n",
       "        [-3.42423558e+00, -3.05836535e+00, -8.84022855e-04,\n",
       "         -5.25592919e-03,  0.00000000e+00],\n",
       "        [-3.45880651e+00, -2.96050978e+00, -3.28963535e-04,\n",
       "         -1.07957248e-03,  0.00000000e+00],\n",
       "        [-3.04116058e+00, -2.11715031e+00, -2.95634673e-05,\n",
       "         -3.23051972e-05,  0.00000000e+00],\n",
       "        [-2.81517220e+00, -2.29944992e+00, -1.85964764e-05,\n",
       "         -1.94309250e-05,  0.00000000e+00],\n",
       "        [-4.75313091e+00, -3.87448597e+00, -1.91362762e+00,\n",
       "         -1.40590742e-02,  0.00000000e+00],\n",
       "        [-4.39468908e+00, -4.73522806e+00, -2.34039187e+00,\n",
       "         -1.47818428e-05,  0.00000000e+00],\n",
       "        [-3.76709151e+00, -4.29335785e+00, -5.37368238e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-3.23364615e+00, -2.63593292e+00, -5.48442900e-01,\n",
       "         -1.43051045e-06,  0.00000000e+00],\n",
       "        [-3.75065637e+00, -2.46172523e+00, -1.45663143e-04,\n",
       "         -1.45434278e-05,  0.00000000e+00],\n",
       "        [-3.51907253e+00, -2.39991903e+00, -1.20632525e-04,\n",
       "         -1.15632338e-05,  0.00000000e+00],\n",
       "        [-4.27934933e+00, -5.33204603e+00, -1.69351304e+00,\n",
       "         -1.70467829e-05,  0.00000000e+00],\n",
       "        [-5.21493816e+00, -2.23726773e+00, -5.16995182e-03,\n",
       "         -2.02655588e-06,  0.00000000e+00],\n",
       "        [-3.48562503e+00, -3.61615300e+00, -9.64789614e-02,\n",
       "         -1.31129354e-05,  0.00000000e+00],\n",
       "        [-4.75313091e+00, -3.87448621e+00, -1.91362762e+00,\n",
       "         -1.40589569e-02,  0.00000000e+00],\n",
       "        [-4.40592432e+00, -2.63214731e+00, -4.28816816e-03,\n",
       "         -2.62260096e-06,  0.00000000e+00],\n",
       "        [-3.35280108e+00, -2.24296212e+00, -6.14941537e-01,\n",
       "         -6.47098660e-01,  0.00000000e+00],\n",
       "        [-3.36524725e+00, -2.20861316e+00, -3.70314694e-04,\n",
       "         -3.09939351e-05,  0.00000000e+00],\n",
       "        [-2.97480106e+00, -2.13650894e+00, -2.53168488e-04,\n",
       "         -2.21726823e-05,  0.00000000e+00],\n",
       "        [-2.72970486e+00, -2.23733521e+00, -2.06687546e-04,\n",
       "         -1.89540970e-05,  0.00000000e+00],\n",
       "        [-3.11209273e+00, -4.85752487e+00, -4.14908171e-01,\n",
       "         -3.69541958e-05,  0.00000000e+00],\n",
       "        [-2.84314108e+00, -2.49576998e+00, -7.97519147e-01,\n",
       "         -4.21911856e-04,  0.00000000e+00],\n",
       "        [-2.84069252e+00, -3.67263174e+00, -1.30233109e+00,\n",
       "         -1.86115061e-03,  0.00000000e+00],\n",
       "        [-3.01517248e+00, -4.00484848e+00, -4.77422893e-01,\n",
       "         -5.12586812e-05,  0.00000000e+00],\n",
       "        [-3.00504208e+00, -4.28788900e+00, -1.65563710e-02,\n",
       "         -7.84366348e-05,  0.00000000e+00],\n",
       "        [-2.97255945e+00, -3.06100368e+00, -7.58158743e-01,\n",
       "         -3.69548115e-06,  0.00000000e+00],\n",
       "        [-2.74036407e+00, -2.52810764e+00, -5.03734648e-01,\n",
       "         -7.15255510e-07,  0.00000000e+00],\n",
       "        [-2.71605659e+00, -2.45513153e+00, -4.03603643e-01,\n",
       "         -7.15255510e-07,  0.00000000e+00],\n",
       "        [-3.30158949e+00, -2.16641426e+00, -8.23702285e-05,\n",
       "         -6.55648955e-06,  0.00000000e+00],\n",
       "        [-3.05658841e+00, -2.06793690e+00, -9.85812221e-05,\n",
       "         -6.43728072e-06,  0.00000000e+00],\n",
       "        [-2.30970478e+00, -2.30431128e+00, -2.79782802e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-2.51144075e+00, -2.22164750e+00, -2.64405400e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-2.31494093e+00, -2.20626450e+00, -2.52895504e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-2.44059539e+00, -2.29967189e+00, -2.17701793e-01,\n",
       "         -5.96046277e-07,  0.00000000e+00],\n",
       "        [-2.40099525e+00, -2.36938643e+00, -2.05650687e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-5.43509007e+00, -3.44119287e+00, -2.03101444e+00,\n",
       "         -1.21284155e-02,  0.00000000e+00],\n",
       "        [-4.54219723e+00, -3.12524033e+00, -1.08540940e+00,\n",
       "         -4.06495419e-05,  0.00000000e+00],\n",
       "        [-4.22533941e+00, -3.03208685e+00, -9.44924593e-01,\n",
       "         -1.66891605e-05,  0.00000000e+00],\n",
       "        [-4.11608267e+00, -2.98528194e+00, -9.23596859e-01,\n",
       "         -1.00135303e-05,  0.00000000e+00],\n",
       "        [-3.67976570e+00, -6.03153944e+00, -2.39527845e+00,\n",
       "         -1.07849345e-01,  0.00000000e+00],\n",
       "        [-5.86099720e+00, -5.04692650e+00, -2.63352275e+00,\n",
       "         -2.10219040e-03,  0.00000000e+00],\n",
       "        [-4.82814455e+00, -6.41683435e+00, -7.88541496e-01,\n",
       "         -4.08565975e-04,  0.00000000e+00],\n",
       "        [-3.05318022e+00, -4.81200409e+00, -5.65316118e-02,\n",
       "         -3.63581712e-05,  0.00000000e+00],\n",
       "        [-4.42986202e+00, -2.75902820e+00, -2.42570648e-03,\n",
       "         -1.33513513e-05,  0.00000000e+00],\n",
       "        [-4.22434235e+00, -3.54178476e+00, -2.23650590e-01,\n",
       "         -1.05733052e-04,  0.00000000e+00],\n",
       "        [-5.59094906e+00, -2.97842956e+00, -2.29171681e+00,\n",
       "         -2.25303011e-05,  0.00000000e+00],\n",
       "        [-3.38545918e+00, -2.33392477e+00, -1.54970876e-05,\n",
       "         -5.72202953e-06,  0.00000000e+00],\n",
       "        [-3.90977716e+00, -4.07491922e+00, -5.08068681e-01,\n",
       "         -7.51015705e-06,  0.00000000e+00],\n",
       "        [-5.26863480e+00, -2.72353768e+00, -1.61652654e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-4.62799549e+00, -2.63918686e+00, -1.85072139e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-4.28707647e+00, -2.71044040e+00, -1.95922256e-01,\n",
       "         -8.34464686e-07,  0.00000000e+00],\n",
       "        [-3.94800782e+00, -2.65166879e+00, -2.17931896e-01,\n",
       "         -1.07288304e-06,  0.00000000e+00],\n",
       "        [-3.33828568e+00, -4.79101229e+00, -1.27094045e-01,\n",
       "         -3.45706349e-06,  0.00000000e+00],\n",
       "        [-3.23061681e+00, -4.42553139e+00, -1.14762962e-01,\n",
       "         -3.69548115e-06,  0.00000000e+00],\n",
       "        [-3.29229546e+00, -2.40489888e+00, -6.46273673e-01,\n",
       "         -1.31130128e-06,  0.00000000e+00],\n",
       "        [-2.91807294e+00, -4.12228823e+00, -1.48847401e-01,\n",
       "         -5.36440348e-06,  0.00000000e+00],\n",
       "        [-2.49136829e+00, -2.19422865e+00, -5.33296347e-01,\n",
       "         -1.43051045e-06,  0.00000000e+00],\n",
       "        [-1.97835612e+00, -4.07560921e+00, -3.01383555e-01,\n",
       "         -1.03711545e-05,  0.00000000e+00],\n",
       "        [-2.01700807e+00, -1.52932298e+00, -2.26495085e-05,\n",
       "         -5.96044674e-06,  0.00000000e+00],\n",
       "        [-1.94872189e+00, -2.95838761e+00, -6.23312175e-01,\n",
       "         -3.51026747e-03,  0.00000000e+00],\n",
       "        [-1.84934855e+00, -2.43213224e+00, -6.80592060e-01,\n",
       "         -1.43051045e-06,  0.00000000e+00],\n",
       "        [-2.28118992e+00, -3.28857017e+00, -6.06670856e-01,\n",
       "         -5.96046277e-07,  0.00000000e+00],\n",
       "        [-2.31906509e+00, -3.24090910e+00, -6.20706141e-01,\n",
       "         -7.15255510e-07,  0.00000000e+00],\n",
       "        [-5.09449100e+00, -3.97381020e+00, -4.84156847e-01,\n",
       "         -2.37436718e-04,  0.00000000e+00],\n",
       "        [-4.42603302e+00, -5.07819748e+00, -2.62611580e+00,\n",
       "         -4.20799952e-05,  0.00000000e+00],\n",
       "        [-2.95943570e+00, -3.60111642e+00, -1.54502773e+00,\n",
       "         -1.01526675e-03,  0.00000000e+00],\n",
       "        [-3.35058284e+00, -2.64545679e+00, -8.93023193e-01,\n",
       "         -1.95501325e-05,  0.00000000e+00],\n",
       "        [-3.88509560e+00, -2.94895792e+00, -3.66384327e-01,\n",
       "         -4.29152533e-06,  0.00000000e+00],\n",
       "        [-3.90297771e+00, -2.74904299e+00, -3.01021844e-01,\n",
       "         -3.33785465e-06,  0.00000000e+00],\n",
       "        [-3.95451021e+00, -2.77529764e+00, -2.53859073e-01,\n",
       "         -3.21864559e-06,  0.00000000e+00],\n",
       "        [-6.01607227e+00, -5.19887066e+00, -2.17874378e-01,\n",
       "         -8.86877751e-05,  0.00000000e+00],\n",
       "        [-3.33556795e+00, -2.25788403e+00, -7.49798346e-05,\n",
       "         -5.66228082e-05,  0.00000000e+00],\n",
       "        [-4.89538050e+00, -2.51558471e+00, -2.01592460e-01,\n",
       "         -3.75502204e-05,  0.00000000e+00],\n",
       "        [-3.39559841e+00, -2.40094924e+00, -1.99077531e-05,\n",
       "         -1.89540970e-05,  0.00000000e+00],\n",
       "        [-6.26717043e+00, -2.36004877e+00, -1.55172152e-02,\n",
       "         -3.26628106e-05, -3.57627812e-07],\n",
       "        [-6.21945286e+00, -2.59675694e+00, -3.25388421e-04,\n",
       "         -1.70097192e-04,  0.00000000e+00],\n",
       "        [-2.99719024e+00, -4.62567568e+00, -1.13831107e-02,\n",
       "         -2.01443414e-04,  0.00000000e+00],\n",
       "        [-2.89420962e+00, -3.01881170e+00, -1.28187227e+00,\n",
       "         -7.55739689e-04,  0.00000000e+00],\n",
       "        [-2.97549582e+00, -2.43312931e+00, -1.12445545e+00,\n",
       "         -6.40782993e-04,  0.00000000e+00],\n",
       "        [-3.06164742e+00, -2.40234566e+00, -8.68853688e-01,\n",
       "         -3.69548115e-06,  0.00000000e+00],\n",
       "        [-4.86375427e+00, -6.53120995e+00, -7.42610991e-02,\n",
       "         -2.29503848e-02,  0.00000000e+00],\n",
       "        [-3.66198683e+00, -4.47035027e+00, -5.43515980e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-3.11420536e+00, -3.56251407e+00, -5.28555632e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-3.73990250e+00, -2.20643806e+00, -1.82373580e-04,\n",
       "         -3.04175832e-04,  0.00000000e+00],\n",
       "        [-3.87796640e+00, -5.32668066e+00, -1.54112351e+00,\n",
       "         -5.36297972e-04,  0.00000000e+00],\n",
       "        [-8.20979595e+00, -1.77377939e+00, -2.67010236e+00,\n",
       "         -2.46760192e-05,  0.00000000e+00],\n",
       "        [-3.58068752e+00, -4.99703312e+00, -1.28505063e+00,\n",
       "         -2.28140561e-04,  0.00000000e+00],\n",
       "        [-5.07212019e+00, -2.55390525e+00, -1.35101914e-01,\n",
       "         -1.19209221e-06,  0.00000000e+00],\n",
       "        [-5.14125633e+00, -2.42719507e+00, -1.59843281e-01,\n",
       "         -1.19209221e-06,  0.00000000e+00],\n",
       "        [-7.17119074e+00, -2.00968194e+00, -2.13687134e+00,\n",
       "         -5.60984109e-03, -3.57627812e-07],\n",
       "        [-2.64708328e+00, -5.06543493e+00, -7.15973154e-02,\n",
       "         -9.55839932e-04,  0.00000000e+00],\n",
       "        [-5.58121490e+00, -5.18203020e+00, -9.94485915e-02,\n",
       "         -8.34464686e-07,  0.00000000e+00],\n",
       "        [-2.50363827e+00, -3.26171947e+00, -6.35476530e-01,\n",
       "         -1.88094564e-04,  0.00000000e+00],\n",
       "        [-3.32070851e+00, -5.39750385e+00, -9.02088359e-03,\n",
       "         -7.29890482e-04,  0.00000000e+00],\n",
       "        [-3.53247690e+00, -2.26750445e+00, -1.34339847e-04,\n",
       "         -8.45158138e-05,  0.00000000e+00],\n",
       "        [-4.80430984e+00, -5.63559628e+00, -4.36504006e-01,\n",
       "         -1.75236128e-05, -1.19209282e-07],\n",
       "        [-4.80125904e+00, -5.99780750e+00, -2.58850176e-02,\n",
       "         -6.55648955e-06,  0.00000000e+00],\n",
       "        [-5.94867706e+00, -4.88658190e+00, -8.03981791e-04,\n",
       "         -2.57488755e-05,  0.00000000e+00],\n",
       "        [-5.71806526e+00, -7.62679482e+00, -1.32453039e-01,\n",
       "         -6.91770576e-04,  0.00000000e+00],\n",
       "        [-3.06438398e+00, -2.18147278e+00, -3.15899633e-05,\n",
       "         -2.72985544e-05,  0.00000000e+00],\n",
       "        [-6.08810997e+00, -2.03753161e+00, -1.69348298e-03,\n",
       "         -6.72055921e-03,  0.00000000e+00],\n",
       "        [-4.93072987e+00, -2.15891075e+00, -5.56909887e-04,\n",
       "         -5.58220490e-04,  0.00000000e+00],\n",
       "        [-4.45108700e+00, -2.31364202e+00, -2.22181436e-04,\n",
       "         -9.30981187e-05,  0.00000000e+00],\n",
       "        [-3.12190676e+00, -2.54631424e+00, -2.60186762e-01,\n",
       "         -2.98022769e-06,  0.00000000e+00],\n",
       "        [-3.03848982e+00, -2.43662953e+00, -2.61861950e-01,\n",
       "         -2.02655588e-06,  0.00000000e+00],\n",
       "        [-2.81898212e+00, -2.13325858e+00, -3.04711074e-01,\n",
       "         -1.66892869e-06,  0.00000000e+00],\n",
       "        [-5.02904558e+00, -3.62412047e+00, -3.79638284e-01,\n",
       "         -6.19886396e-06,  0.00000000e+00],\n",
       "        [-3.79454494e+00, -2.68443274e+00, -3.30727398e-02,\n",
       "         -3.34181219e-01,  0.00000000e+00],\n",
       "        [-3.20561814e+00, -2.45992231e+00, -2.33294773e+00,\n",
       "         -4.74578759e-04,  0.00000000e+00],\n",
       "        [-2.34826660e+00, -2.43017888e+00, -3.34730893e-02,\n",
       "         -2.12115332e-01,  0.00000000e+00],\n",
       "        [-2.02307916e+00, -2.43247366e+00, -3.24356779e-02,\n",
       "         -2.01053247e-01,  0.00000000e+00],\n",
       "        [-3.73714209e+00, -4.14542103e+00, -8.07323694e-01,\n",
       "         -3.52853276e-05,  0.00000000e+00],\n",
       "        [-3.33068323e+00, -4.00291538e+00, -7.98333287e-01,\n",
       "         -8.98797662e-05,  0.00000000e+00],\n",
       "        [-2.80820489e+00, -4.06607628e+00, -8.68205667e-01,\n",
       "         -8.02246359e-05,  0.00000000e+00],\n",
       "        [-2.54134083e+00, -4.10789776e+00, -9.47799146e-01,\n",
       "         -7.10462118e-05,  0.00000000e+00],\n",
       "        [-2.53339219e+00, -3.12405348e+00, -1.80824136e-04,\n",
       "         -3.02787012e-05,  0.00000000e+00],\n",
       "        [-2.36766362e+00, -3.07406592e+00, -1.67832593e-04,\n",
       "         -3.00402899e-05,  0.00000000e+00],\n",
       "        [-2.43290091e+00, -3.07487082e+00, -1.40299497e-04,\n",
       "         -2.82522033e-05,  0.00000000e+00],\n",
       "        [-2.04436350e+00, -2.97756743e+00, -1.28856933e-04,\n",
       "         -3.17091690e-05,  0.00000000e+00],\n",
       "        [-1.82797289e+00, -2.98120594e+00, -1.08236178e-04,\n",
       "         -3.56429409e-05,  0.00000000e+00],\n",
       "        [-1.50955927e+00, -2.83691764e+00, -9.69124594e-05,\n",
       "         -3.50469163e-05,  0.00000000e+00],\n",
       "        [-1.04508090e+00, -2.71478081e+00, -9.09525552e-05,\n",
       "         -3.69541958e-05,  0.00000000e+00],\n",
       "        [-9.01820600e-01, -2.61839771e+00, -9.15485434e-05,\n",
       "         -3.09939351e-05,  0.00000000e+00],\n",
       "        [-9.19079304e-01, -2.59204435e+00, -8.67805938e-05,\n",
       "         -3.48085050e-05,  0.00000000e+00],\n",
       "        [-9.97953117e-01, -2.68827343e+00, -7.36686270e-05,\n",
       "         -3.62389692e-05,  0.00000000e+00],\n",
       "        [-9.48252916e-01, -2.74288917e+00, -5.82916437e-05,\n",
       "         -3.21859916e-05,  0.00000000e+00],\n",
       "        [-1.11769378e+00, -3.13831234e+00, -7.08683312e-01,\n",
       "         -3.93382907e-05, -1.19209282e-07]], dtype=float32),\n",
       " 'objective/ref_logprobs': array([[-3.76126862e+00, -4.91392851e+00, -1.44429564e+00,\n",
       "         -3.39802384e-01,  0.00000000e+00],\n",
       "        [-3.30107641e+00, -1.97480762e+00, -1.94255662e+00,\n",
       "         -7.31331706e-01,  0.00000000e+00],\n",
       "        [-3.42423558e+00, -3.05836535e+00, -8.84022855e-04,\n",
       "         -5.25592919e-03,  0.00000000e+00],\n",
       "        [-3.45880651e+00, -2.96050978e+00, -3.28963535e-04,\n",
       "         -1.07957248e-03,  0.00000000e+00],\n",
       "        [-3.04116058e+00, -2.11715031e+00, -2.95634673e-05,\n",
       "         -3.23051972e-05,  0.00000000e+00],\n",
       "        [-2.81517220e+00, -2.29944992e+00, -1.85964764e-05,\n",
       "         -1.94309250e-05,  0.00000000e+00],\n",
       "        [-4.75313091e+00, -3.87448597e+00, -1.91362762e+00,\n",
       "         -1.40590742e-02,  0.00000000e+00],\n",
       "        [-4.39468908e+00, -4.73522806e+00, -2.34039187e+00,\n",
       "         -1.47818428e-05,  0.00000000e+00],\n",
       "        [-3.76709151e+00, -4.29335785e+00, -5.37368238e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-3.23364615e+00, -2.63593292e+00, -5.48442900e-01,\n",
       "         -1.43051045e-06,  0.00000000e+00],\n",
       "        [-3.75065637e+00, -2.46172523e+00, -1.45663143e-04,\n",
       "         -1.45434278e-05,  0.00000000e+00],\n",
       "        [-3.51907253e+00, -2.39991903e+00, -1.20632525e-04,\n",
       "         -1.15632338e-05,  0.00000000e+00],\n",
       "        [-4.27934933e+00, -5.33204603e+00, -1.69351304e+00,\n",
       "         -1.70467829e-05,  0.00000000e+00],\n",
       "        [-5.21493816e+00, -2.23726773e+00, -5.16995182e-03,\n",
       "         -2.02655588e-06,  0.00000000e+00],\n",
       "        [-3.48562503e+00, -3.61615300e+00, -9.64789614e-02,\n",
       "         -1.31129354e-05,  0.00000000e+00],\n",
       "        [-4.75313091e+00, -3.87448621e+00, -1.91362762e+00,\n",
       "         -1.40589569e-02,  0.00000000e+00],\n",
       "        [-4.40592432e+00, -2.63214731e+00, -4.28816816e-03,\n",
       "         -2.62260096e-06,  0.00000000e+00],\n",
       "        [-3.35280108e+00, -2.24296212e+00, -6.14941537e-01,\n",
       "         -6.47098660e-01,  0.00000000e+00],\n",
       "        [-3.36524725e+00, -2.20861316e+00, -3.70314694e-04,\n",
       "         -3.09939351e-05,  0.00000000e+00],\n",
       "        [-2.97480106e+00, -2.13650894e+00, -2.53168488e-04,\n",
       "         -2.21726823e-05,  0.00000000e+00],\n",
       "        [-2.72970486e+00, -2.23733521e+00, -2.06687546e-04,\n",
       "         -1.89540970e-05,  0.00000000e+00],\n",
       "        [-3.11209273e+00, -4.85752487e+00, -4.14908171e-01,\n",
       "         -3.69541958e-05,  0.00000000e+00],\n",
       "        [-2.84314108e+00, -2.49576998e+00, -7.97519147e-01,\n",
       "         -4.21911856e-04,  0.00000000e+00],\n",
       "        [-2.84069252e+00, -3.67263174e+00, -1.30233109e+00,\n",
       "         -1.86115061e-03,  0.00000000e+00],\n",
       "        [-3.01517248e+00, -4.00484848e+00, -4.77422893e-01,\n",
       "         -5.12586812e-05,  0.00000000e+00],\n",
       "        [-3.00504208e+00, -4.28788900e+00, -1.65563710e-02,\n",
       "         -7.84366348e-05,  0.00000000e+00],\n",
       "        [-2.97255945e+00, -3.06100368e+00, -7.58158743e-01,\n",
       "         -3.69548115e-06,  0.00000000e+00],\n",
       "        [-2.74036407e+00, -2.52810764e+00, -5.03734648e-01,\n",
       "         -7.15255510e-07,  0.00000000e+00],\n",
       "        [-2.71605659e+00, -2.45513153e+00, -4.03603643e-01,\n",
       "         -7.15255510e-07,  0.00000000e+00],\n",
       "        [-3.30158949e+00, -2.16641426e+00, -8.23702285e-05,\n",
       "         -6.55648955e-06,  0.00000000e+00],\n",
       "        [-3.05658841e+00, -2.06793690e+00, -9.85812221e-05,\n",
       "         -6.43728072e-06,  0.00000000e+00],\n",
       "        [-2.30970478e+00, -2.30431128e+00, -2.79782802e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-2.51144075e+00, -2.22164750e+00, -2.64405400e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-2.31494093e+00, -2.20626450e+00, -2.52895504e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-2.44059539e+00, -2.29967189e+00, -2.17701793e-01,\n",
       "         -5.96046277e-07,  0.00000000e+00],\n",
       "        [-2.40099525e+00, -2.36938643e+00, -2.05650687e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-5.43509007e+00, -3.44119287e+00, -2.03101444e+00,\n",
       "         -1.21284155e-02,  0.00000000e+00],\n",
       "        [-4.54219723e+00, -3.12524033e+00, -1.08540940e+00,\n",
       "         -4.06495419e-05,  0.00000000e+00],\n",
       "        [-4.22533941e+00, -3.03208685e+00, -9.44924593e-01,\n",
       "         -1.66891605e-05,  0.00000000e+00],\n",
       "        [-4.11608267e+00, -2.98528194e+00, -9.23596859e-01,\n",
       "         -1.00135303e-05,  0.00000000e+00],\n",
       "        [-3.67976570e+00, -6.03153944e+00, -2.39527845e+00,\n",
       "         -1.07849345e-01,  0.00000000e+00],\n",
       "        [-5.86099720e+00, -5.04692650e+00, -2.63352275e+00,\n",
       "         -2.10219040e-03,  0.00000000e+00],\n",
       "        [-4.82814455e+00, -6.41683435e+00, -7.88541496e-01,\n",
       "         -4.08565975e-04,  0.00000000e+00],\n",
       "        [-3.05318022e+00, -4.81200409e+00, -5.65316118e-02,\n",
       "         -3.63581712e-05,  0.00000000e+00],\n",
       "        [-4.42986202e+00, -2.75902820e+00, -2.42570648e-03,\n",
       "         -1.33513513e-05,  0.00000000e+00],\n",
       "        [-4.22434235e+00, -3.54178476e+00, -2.23650590e-01,\n",
       "         -1.05733052e-04,  0.00000000e+00],\n",
       "        [-5.59094906e+00, -2.97842956e+00, -2.29171681e+00,\n",
       "         -2.25303011e-05,  0.00000000e+00],\n",
       "        [-3.38545918e+00, -2.33392477e+00, -1.54970876e-05,\n",
       "         -5.72202953e-06,  0.00000000e+00],\n",
       "        [-3.90977716e+00, -4.07491922e+00, -5.08068681e-01,\n",
       "         -7.51015705e-06,  0.00000000e+00],\n",
       "        [-5.26863480e+00, -2.72353768e+00, -1.61652654e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-4.62799549e+00, -2.63918686e+00, -1.85072139e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-4.28707647e+00, -2.71044040e+00, -1.95922256e-01,\n",
       "         -8.34464686e-07,  0.00000000e+00],\n",
       "        [-3.94800782e+00, -2.65166879e+00, -2.17931896e-01,\n",
       "         -1.07288304e-06,  0.00000000e+00],\n",
       "        [-3.33828568e+00, -4.79101229e+00, -1.27094045e-01,\n",
       "         -3.45706349e-06,  0.00000000e+00],\n",
       "        [-3.23061681e+00, -4.42553139e+00, -1.14762962e-01,\n",
       "         -3.69548115e-06,  0.00000000e+00],\n",
       "        [-3.29229546e+00, -2.40489888e+00, -6.46273673e-01,\n",
       "         -1.31130128e-06,  0.00000000e+00],\n",
       "        [-2.91807294e+00, -4.12228823e+00, -1.48847401e-01,\n",
       "         -5.36440348e-06,  0.00000000e+00],\n",
       "        [-2.49136829e+00, -2.19422865e+00, -5.33296347e-01,\n",
       "         -1.43051045e-06,  0.00000000e+00],\n",
       "        [-1.97835612e+00, -4.07560921e+00, -3.01383555e-01,\n",
       "         -1.03711545e-05,  0.00000000e+00],\n",
       "        [-2.01700807e+00, -1.52932298e+00, -2.26495085e-05,\n",
       "         -5.96044674e-06,  0.00000000e+00],\n",
       "        [-1.94872189e+00, -2.95838761e+00, -6.23312175e-01,\n",
       "         -3.51026747e-03,  0.00000000e+00],\n",
       "        [-1.84934855e+00, -2.43213224e+00, -6.80592060e-01,\n",
       "         -1.43051045e-06,  0.00000000e+00],\n",
       "        [-2.28118992e+00, -3.28857017e+00, -6.06670856e-01,\n",
       "         -5.96046277e-07,  0.00000000e+00],\n",
       "        [-2.31906509e+00, -3.24090910e+00, -6.20706141e-01,\n",
       "         -7.15255510e-07,  0.00000000e+00],\n",
       "        [-5.09449100e+00, -3.97381020e+00, -4.84156847e-01,\n",
       "         -2.37436718e-04,  0.00000000e+00],\n",
       "        [-4.42603302e+00, -5.07819748e+00, -2.62611580e+00,\n",
       "         -4.20799952e-05,  0.00000000e+00],\n",
       "        [-2.95943570e+00, -3.60111642e+00, -1.54502773e+00,\n",
       "         -1.01526675e-03,  0.00000000e+00],\n",
       "        [-3.35058284e+00, -2.64545679e+00, -8.93023193e-01,\n",
       "         -1.95501325e-05,  0.00000000e+00],\n",
       "        [-3.88509560e+00, -2.94895792e+00, -3.66384327e-01,\n",
       "         -4.29152533e-06,  0.00000000e+00],\n",
       "        [-3.90297771e+00, -2.74904299e+00, -3.01021844e-01,\n",
       "         -3.33785465e-06,  0.00000000e+00],\n",
       "        [-3.95451021e+00, -2.77529764e+00, -2.53859073e-01,\n",
       "         -3.21864559e-06,  0.00000000e+00],\n",
       "        [-6.01607227e+00, -5.19887066e+00, -2.17874378e-01,\n",
       "         -8.86877751e-05,  0.00000000e+00],\n",
       "        [-3.33556795e+00, -2.25788403e+00, -7.49798346e-05,\n",
       "         -5.66228082e-05,  0.00000000e+00],\n",
       "        [-4.89538050e+00, -2.51558471e+00, -2.01592460e-01,\n",
       "         -3.75502204e-05,  0.00000000e+00],\n",
       "        [-3.39559841e+00, -2.40094924e+00, -1.99077531e-05,\n",
       "         -1.89540970e-05,  0.00000000e+00],\n",
       "        [-6.26717043e+00, -2.36004877e+00, -1.55172152e-02,\n",
       "         -3.26628106e-05, -3.57627812e-07],\n",
       "        [-6.21945286e+00, -2.59675694e+00, -3.25388421e-04,\n",
       "         -1.70097192e-04,  0.00000000e+00],\n",
       "        [-2.99719024e+00, -4.62567568e+00, -1.13831107e-02,\n",
       "         -2.01443414e-04,  0.00000000e+00],\n",
       "        [-2.89420962e+00, -3.01881170e+00, -1.28187227e+00,\n",
       "         -7.55739689e-04,  0.00000000e+00],\n",
       "        [-2.97549582e+00, -2.43312931e+00, -1.12445545e+00,\n",
       "         -6.40782993e-04,  0.00000000e+00],\n",
       "        [-3.06164742e+00, -2.40234566e+00, -8.68853688e-01,\n",
       "         -3.69548115e-06,  0.00000000e+00],\n",
       "        [-4.86375427e+00, -6.53120995e+00, -7.42610991e-02,\n",
       "         -2.29503848e-02,  0.00000000e+00],\n",
       "        [-3.66198683e+00, -4.47035027e+00, -5.43515980e-01,\n",
       "         -9.53673862e-07,  0.00000000e+00],\n",
       "        [-3.11420536e+00, -3.56251407e+00, -5.28555632e-01,\n",
       "         -4.76837045e-07,  0.00000000e+00],\n",
       "        [-3.73990250e+00, -2.20643806e+00, -1.82373580e-04,\n",
       "         -3.04175832e-04,  0.00000000e+00],\n",
       "        [-3.87796640e+00, -5.32668066e+00, -1.54112351e+00,\n",
       "         -5.36297972e-04,  0.00000000e+00],\n",
       "        [-8.20979595e+00, -1.77377939e+00, -2.67010236e+00,\n",
       "         -2.46760192e-05,  0.00000000e+00],\n",
       "        [-3.58068752e+00, -4.99703312e+00, -1.28505063e+00,\n",
       "         -2.28140561e-04,  0.00000000e+00],\n",
       "        [-5.07212019e+00, -2.55390525e+00, -1.35101914e-01,\n",
       "         -1.19209221e-06,  0.00000000e+00],\n",
       "        [-5.14125633e+00, -2.42719507e+00, -1.59843281e-01,\n",
       "         -1.19209221e-06,  0.00000000e+00],\n",
       "        [-7.17119074e+00, -2.00968194e+00, -2.13687134e+00,\n",
       "         -5.60984109e-03, -3.57627812e-07],\n",
       "        [-2.64708328e+00, -5.06543493e+00, -7.15973154e-02,\n",
       "         -9.55839932e-04,  0.00000000e+00],\n",
       "        [-5.58121490e+00, -5.18203020e+00, -9.94485915e-02,\n",
       "         -8.34464686e-07,  0.00000000e+00],\n",
       "        [-2.50363827e+00, -3.26171947e+00, -6.35476530e-01,\n",
       "         -1.88094564e-04,  0.00000000e+00],\n",
       "        [-3.32070851e+00, -5.39750385e+00, -9.02088359e-03,\n",
       "         -7.29890482e-04,  0.00000000e+00],\n",
       "        [-3.53247690e+00, -2.26750445e+00, -1.34339847e-04,\n",
       "         -8.45158138e-05,  0.00000000e+00],\n",
       "        [-4.80430984e+00, -5.63559628e+00, -4.36504006e-01,\n",
       "         -1.75236128e-05, -1.19209282e-07],\n",
       "        [-4.80125904e+00, -5.99780750e+00, -2.58850176e-02,\n",
       "         -6.55648955e-06,  0.00000000e+00],\n",
       "        [-5.94867706e+00, -4.88658190e+00, -8.03981791e-04,\n",
       "         -2.57488755e-05,  0.00000000e+00],\n",
       "        [-5.71806526e+00, -7.62679482e+00, -1.32453039e-01,\n",
       "         -6.91770576e-04,  0.00000000e+00],\n",
       "        [-3.06438398e+00, -2.18147278e+00, -3.15899633e-05,\n",
       "         -2.72985544e-05,  0.00000000e+00],\n",
       "        [-6.08810997e+00, -2.03753161e+00, -1.69348298e-03,\n",
       "         -6.72055921e-03,  0.00000000e+00],\n",
       "        [-4.93072987e+00, -2.15891075e+00, -5.56909887e-04,\n",
       "         -5.58220490e-04,  0.00000000e+00],\n",
       "        [-4.45108700e+00, -2.31364202e+00, -2.22181436e-04,\n",
       "         -9.30981187e-05,  0.00000000e+00],\n",
       "        [-3.12190676e+00, -2.54631424e+00, -2.60186762e-01,\n",
       "         -2.98022769e-06,  0.00000000e+00],\n",
       "        [-3.03848982e+00, -2.43662953e+00, -2.61861950e-01,\n",
       "         -2.02655588e-06,  0.00000000e+00],\n",
       "        [-2.81898212e+00, -2.13325858e+00, -3.04711074e-01,\n",
       "         -1.66892869e-06,  0.00000000e+00],\n",
       "        [-5.02904558e+00, -3.62412047e+00, -3.79638284e-01,\n",
       "         -6.19886396e-06,  0.00000000e+00],\n",
       "        [-3.79454494e+00, -2.68443274e+00, -3.30727398e-02,\n",
       "         -3.34181219e-01,  0.00000000e+00],\n",
       "        [-3.20561814e+00, -2.45992231e+00, -2.33294773e+00,\n",
       "         -4.74578759e-04,  0.00000000e+00],\n",
       "        [-2.34826660e+00, -2.43017888e+00, -3.34730893e-02,\n",
       "         -2.12115332e-01,  0.00000000e+00],\n",
       "        [-2.02307916e+00, -2.43247366e+00, -3.24356779e-02,\n",
       "         -2.01053247e-01,  0.00000000e+00],\n",
       "        [-3.73714209e+00, -4.14542103e+00, -8.07323694e-01,\n",
       "         -3.52853276e-05,  0.00000000e+00],\n",
       "        [-3.33068323e+00, -4.00291538e+00, -7.98333287e-01,\n",
       "         -8.98797662e-05,  0.00000000e+00],\n",
       "        [-2.80820489e+00, -4.06607628e+00, -8.68205667e-01,\n",
       "         -8.02246359e-05,  0.00000000e+00],\n",
       "        [-2.54134083e+00, -4.10789776e+00, -9.47799146e-01,\n",
       "         -7.10462118e-05,  0.00000000e+00],\n",
       "        [-2.53339219e+00, -3.12405348e+00, -1.80824136e-04,\n",
       "         -3.02787012e-05,  0.00000000e+00],\n",
       "        [-2.36766362e+00, -3.07406592e+00, -1.67832593e-04,\n",
       "         -3.00402899e-05,  0.00000000e+00],\n",
       "        [-2.43290091e+00, -3.07487082e+00, -1.40299497e-04,\n",
       "         -2.82522033e-05,  0.00000000e+00],\n",
       "        [-2.04436350e+00, -2.97756743e+00, -1.28856933e-04,\n",
       "         -3.17091690e-05,  0.00000000e+00],\n",
       "        [-1.82797289e+00, -2.98120594e+00, -1.08236178e-04,\n",
       "         -3.56429409e-05,  0.00000000e+00],\n",
       "        [-1.50955927e+00, -2.83691764e+00, -9.69124594e-05,\n",
       "         -3.50469163e-05,  0.00000000e+00],\n",
       "        [-1.04508090e+00, -2.71478081e+00, -9.09525552e-05,\n",
       "         -3.69541958e-05,  0.00000000e+00],\n",
       "        [-9.01820600e-01, -2.61839771e+00, -9.15485434e-05,\n",
       "         -3.09939351e-05,  0.00000000e+00],\n",
       "        [-9.19079304e-01, -2.59204435e+00, -8.67805938e-05,\n",
       "         -3.48085050e-05,  0.00000000e+00],\n",
       "        [-9.97953117e-01, -2.68827343e+00, -7.36686270e-05,\n",
       "         -3.62389692e-05,  0.00000000e+00],\n",
       "        [-9.48252916e-01, -2.74288917e+00, -5.82916437e-05,\n",
       "         -3.21859916e-05,  0.00000000e+00],\n",
       "        [-1.11769378e+00, -3.13831234e+00, -7.08683312e-01,\n",
       "         -3.93382907e-05, -1.19209282e-07]], dtype=float32),\n",
       " 'objective/kl_coef': 0.2,\n",
       " 'objective/entropy': 3.8141984939575195,\n",
       " 'ppo/mean_non_score_reward': 0.0,\n",
       " 'ppo/mean_scores': 0.7886272668838501,\n",
       " 'ppo/std_scores': 0.2477816641330719,\n",
       " 'tokens/queries_len_mean': 81.0,\n",
       " 'tokens/queries_len_std': 0.0,\n",
       " 'tokens/queries_dist': array([81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.,\n",
       "        81., 81., 81., 81., 81., 81., 81., 81., 81., 81., 81.],\n",
       "       dtype=float32),\n",
       " 'tokens/responses_len_mean': 6.0,\n",
       " 'tokens/responses_len_std': 0.0,\n",
       " 'tokens/responses_dist': array([6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "        6., 6., 6., 6., 6., 6., 6., 6., 6.], dtype=float32),\n",
       " 'ppo/loss/policy': -0.016260996460914612,\n",
       " 'ppo/loss/value': 1.173297643661499,\n",
       " 'ppo/loss/total': 0.10106877237558365,\n",
       " 'ppo/policy/entropy': 1.306699514389038,\n",
       " 'ppo/policy/approxkl': 0.002897932194173336,\n",
       " 'ppo/policy/policykl': 0.01834796741604805,\n",
       " 'ppo/policy/clipfrac': 0.0341796875,\n",
       " 'ppo/policy/advantages': array([ 0.22605154, -0.7307447 , -0.53476304, ...,  0.5571793 ,\n",
       "        -0.3377677 , -0.84302694], shape=(2560,), dtype=float32),\n",
       " 'ppo/policy/advantages_mean': -6.51925802230835e-09,\n",
       " 'ppo/policy/ratio': array([1.        , 1.        , 1.        , ..., 1.0000114 , 0.99999774,\n",
       "        1.        ], shape=(2560,), dtype=float32),\n",
       " 'ppo/returns/mean': 0.7679146528244019,\n",
       " 'ppo/returns/var': 0.05600140243768692,\n",
       " 'ppo/val/vpred': 0.40084853768348694,\n",
       " 'ppo/val/error': 2.3209805488586426,\n",
       " 'ppo/val/clipfrac': 0.06884765625,\n",
       " 'ppo/val/mean': 0.3574836850166321,\n",
       " 'ppo/val/var': 2.184626579284668,\n",
       " 'ppo/val/var_explained': -40.44504165649414,\n",
       " 'ppo/learning_rate': 1.41e-05,\n",
       " 'time/ppo/forward_pass': 0.10755157470703125,\n",
       " 'time/ppo/compute_rewards': 0.02568340301513672,\n",
       " 'time/ppo/compute_advantages': 0.0013782978057861328,\n",
       " 'time/ppo/optimize_step': 0.40131068229675293,\n",
       " 'time/ppo/calc_stats': 0.007813692092895508,\n",
       " 'time/ppo/total': 0.5440042018890381}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 32173, 32550, 32756, 32847,     1],\n",
       "        [    0, 32173, 32550, 32756, 32847,     1],\n",
       "        [    0, 32223, 32513, 32649, 32858,     1],\n",
       "        [    0, 32117, 32465, 32798, 33035,     1],\n",
       "        [    0, 32118, 32513, 32600, 32869,     1],\n",
       "        [    0, 32118, 32513, 32600, 32869,     1],\n",
       "        [    0, 32167, 32475, 32561, 32881,     1],\n",
       "        [    0, 32192, 32309, 32657, 32875,     1],\n",
       "        [    0, 32192, 32475, 32653, 32889,     1],\n",
       "        [    0, 32192, 32489, 32569, 32985,     1],\n",
       "        [    0, 32192, 32489, 32569, 32985,     1],\n",
       "        [    0, 32192, 32489, 32569, 32985,     1],\n",
       "        [    0, 32192, 32475, 32653, 32889,     1],\n",
       "        [    0, 32287, 32461, 32590, 33027,     1],\n",
       "        [    0, 32192, 32475, 32653, 32889,     1],\n",
       "        [    0, 32167, 32475, 32561, 32881,     1],\n",
       "        [    0, 32178, 32464, 32683, 32979,     1],\n",
       "        [    0, 32178, 32464, 32683, 32979,     1],\n",
       "        [    0, 32287, 32513, 32800, 32905,     1],\n",
       "        [    0, 32287, 32513, 32800, 32905,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Source:      /root/miniconda3/envs/py310\n",
      "Destination: /root/miniconda3/envs/ppo\n",
      "Packages: 25\n",
      "Files: 41067\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate ppo\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create -n ppo --clone py310\n",
    "conda activate ppo\n",
    "pip install trl==0.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from trl import GRPOConfig, GRPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from time import time\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "def check_collision(all_indices_str):\n",
    "    tot_item = len(all_indices_str)\n",
    "    tot_indice = len(set(all_indices_str.tolist()))\n",
    "    return tot_item==tot_indice\n",
    "\n",
    "def get_indices_count(all_indices_str):\n",
    "    indices_count = collections.defaultdict(int)\n",
    "    for index in all_indices_str:\n",
    "        indices_count[index] += 1\n",
    "    return indices_count\n",
    "\n",
    "def get_collision_item(all_indices_str):\n",
    "    index2id = {}\n",
    "    for i, index in enumerate(all_indices_str):\n",
    "        if index not in index2id:\n",
    "            index2id[index] = []\n",
    "        index2id[index].append(i)\n",
    "\n",
    "    collision_item_groups = []\n",
    "\n",
    "    for index in index2id:\n",
    "        if len(index2id[index]) > 1:\n",
    "            collision_item_groups.append(index2id[index])\n",
    "\n",
    "    return collision_item_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='Yelp'\n",
    "input_file=f'/root/LETTER/data/{dataset}/{dataset}.index.json'\n",
    "output_file=f'/root/LETTER/data/{dataset}/{dataset}.new.index.json'\n",
    "with open(input_file, 'r') as fp:\n",
    "    all_indices_dict = json.load(fp)\n",
    "all_indices = list(all_indices_dict.values())\n",
    "all_indices=np.array(all_indices)\n",
    "all_indices_str = np.array([str(i) for i in all_indices])\n",
    "check_collision(all_indices_str)\n",
    "collision_item_groups = get_collision_item(all_indices_str)\n",
    "prefix = [\"<a_{}>\",\"<b_{}>\",\"<c_{}>\",\"<d_{}>\",\"<e_{}>\",\"<f_{}>\"]\n",
    "origin_len = len(all_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_indices = np.c_[all_indices,np.repeat(prefix[all_indices.shape[-1]].format(0), all_indices.shape[0]).reshape(-1, 1)]\n",
    "# all_indices_str = np.array([str(i) for i in all_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for collision in collision_item_groups:\n",
    "    for i in range(1,len(collision)):\n",
    "        origin_prefix = all_indices[collision[i]][:-1]\n",
    "        all_indices[collision[i]]= np.concatenate([origin_prefix,np.array([prefix[origin_len-1].format(int(i+110))])],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_indices\n",
    "all_indices_str = np.array([str(i) for i in all_indices])\n",
    "collision_item_groups = get_collision_item(all_indices_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['<a_80>' '<b_235>' '<c_240>' '<d_54>']\",\n",
       "       \"['<a_173>' '<b_238>' '<c_127>' '<d_104>']\",\n",
       "       \"['<a_139>' '<b_251>' '<c_235>' '<d_202>']\", ...,\n",
       "       \"['<a_222>' '<b_74>' '<c_57>' '<d_212>']\",\n",
       "       \"['<a_203>' '<b_240>' '<c_233>' '<d_184>']\",\n",
       "       \"['<a_190>' '<b_157>' '<c_28>' '<d_133>']\"],\n",
       "      shape=(20033,), dtype='<U41')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indices_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_indices_dict = {}\n",
    "for item, indices in enumerate(all_indices.tolist()):\n",
    "    all_indices_dict[item] = list(indices)\n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    json.dump(all_indices_dict,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision_item_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<a_226>', '<b_162>', '<c_212>', '<d_2>'], dtype='<U7')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indices[8371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
